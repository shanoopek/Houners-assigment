{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HonoursAssignment1-Code.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Loading the data and splitting it into train and test sets"
      ],
      "metadata": {
        "id": "EGH-N7DmheSk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Muhammad Shanoop E K\n",
        "Roll No:43\n",
        "TVE19CS044"
      ],
      "metadata": {
        "id": "iEXRVcPx-W5Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# x_train: (60000, 28, 28)\n",
        "# y_train: (10000, 28, 28)\n",
        "\n",
        "x_train, x_test = x_train / 255, x_test / 255"
      ],
      "metadata": {
        "id": "pZ0xBZXJLsW-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 1\n",
        "Here the layers are: 1 input layer having 784 neurons, 1 hidden layer having 32 units and 1 output layers having 10 units (10 classes). The count of total parameters is 25450 which is much less than the training size of 60000.\n",
        "Hidden layer uses 'ReLU' activation function and output layers uses softmax.\n",
        "Model is trained for 5 epochs."
      ],
      "metadata": {
        "id": "sJHOE8D4i0AQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "  tf.keras.layers.Dense(32, activation='relu'),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "\n",
        "model1.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])\n",
        "model1.summary()\n",
        "\n",
        "print(\"Training...\")\n",
        "model1.fit(x_train, y_train, epochs=5)\n",
        "\n",
        "print(\"Testing...\")\n",
        "model1.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7SFmt31VS9KR",
        "outputId": "3f79043a-7c2a-4aad-fc21-f228b6835086"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 784)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 32)                25120     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                330       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25,450\n",
            "Trainable params: 25,450\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Training...\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.3580 - accuracy: 0.8988\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1872 - accuracy: 0.9462\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.1436 - accuracy: 0.9580\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.1187 - accuracy: 0.9649\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.1020 - accuracy: 0.9697\n",
            "Testing...\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1129 - accuracy: 0.9650\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.11288090795278549, 0.9649999737739563]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 1:\n",
        "\n",
        "*   Number of epochs = 5 \n",
        "*   Training Accuracy = 0.9691\n",
        "*   Test Accuray = 0.9627\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "t7x6c8J-h2Z7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 2\n",
        "\n",
        "Layers are: 1 input layer having 784 neurons, 2 hidden layers, one having 64 units and other having 32 units and 1 output layers having 10 units (10 classes).The count of total parameters is 52650 which is really close to the training size of 60000, so there is high chance that this model will suffer from overfitting.\n",
        "Hidden layers uses 'ReLU' activation function and output layers uses softmax.\n",
        "Model is trained for 20 epochs."
      ],
      "metadata": {
        "id": "rsGqQVpmlyqK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "  tf.keras.layers.Dense(64, activation='relu'),\n",
        "  tf.keras.layers.Dense(32, activation='relu'),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "\n",
        "model2.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])\n",
        "model2.summary()\n",
        "\n",
        "print(\"Training...\")\n",
        "model1.fit(x_train, y_train, epochs=20)\n",
        "\n",
        "print(\"Testing...\")\n",
        "model1.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHqbOgi8Uk9R",
        "outputId": "4bf31d78-4d7f-4535-c8ca-7f723289e43e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_1 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                50240     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 10)                330       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 52,650\n",
            "Trainable params: 52,650\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Training...\n",
            "Epoch 1/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0897 - accuracy: 0.9734\n",
            "Epoch 2/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0806 - accuracy: 0.9760\n",
            "Epoch 3/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0732 - accuracy: 0.9778\n",
            "Epoch 4/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0674 - accuracy: 0.9792\n",
            "Epoch 5/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0619 - accuracy: 0.9808\n",
            "Epoch 6/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0575 - accuracy: 0.9823\n",
            "Epoch 7/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0532 - accuracy: 0.9834\n",
            "Epoch 8/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0501 - accuracy: 0.9843\n",
            "Epoch 9/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0463 - accuracy: 0.9859\n",
            "Epoch 10/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0438 - accuracy: 0.9864\n",
            "Epoch 11/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0411 - accuracy: 0.9873\n",
            "Epoch 12/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0394 - accuracy: 0.9876\n",
            "Epoch 13/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0360 - accuracy: 0.9890\n",
            "Epoch 14/20\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0349 - accuracy: 0.9890\n",
            "Epoch 15/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0327 - accuracy: 0.9897\n",
            "Epoch 16/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0308 - accuracy: 0.9905\n",
            "Epoch 17/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0290 - accuracy: 0.9913\n",
            "Epoch 18/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0273 - accuracy: 0.9916\n",
            "Epoch 19/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0265 - accuracy: 0.9917\n",
            "Epoch 20/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0247 - accuracy: 0.9923\n",
            "Testing...\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1251 - accuracy: 0.9680\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.12507741153240204, 0.9679999947547913]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 2:\n",
        "\n",
        "*   Number of epochs = 20\n",
        "*   Training Accuracy = 0.9961\n",
        "*   Test Accuray = 0.9673\n"
      ],
      "metadata": {
        "id": "c06uryjTmiKr"
      }
    }
  ]
}